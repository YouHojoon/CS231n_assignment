{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FullyConnectedNets.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "193c90baf5554ad0a58ef7d6ef248d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a5442f6331c745928fb68d43ae9f4ff1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_176fa6b1d3164536926800f5ff50f58a",
              "IPY_MODEL_cdca0bb9d6d741f88090fb5fc87d892b"
            ]
          }
        },
        "a5442f6331c745928fb68d43ae9f4ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "176fa6b1d3164536926800f5ff50f58a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bf6b7923426b46b396a9baf432637712",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0d1798f57d14e1299813930562a6dc0"
          }
        },
        "cdca0bb9d6d741f88090fb5fc87d892b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0a8c31dabd494472b23a6c8746a523b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [21:36&lt;00:00, 131519.64it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eac1a8ec449840ff8794e62534463d9d"
          }
        },
        "bf6b7923426b46b396a9baf432637712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0d1798f57d14e1299813930562a6dc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a8c31dabd494472b23a6c8746a523b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eac1a8ec449840ff8794e62534463d9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J82qSV_gsSs-",
        "outputId": "38274082-5a78-45c1-ca51-8291c7f0e104"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import pickle as pickle\n",
        "import optim as optim\n",
        "from torchvision.datasets import CIFAR10\n",
        "from loss import *\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0,8.0)\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "def rel_error(x, y):\n",
        "  \"\"\" returns relative error \"\"\"\n",
        "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5OwgPpyuFKQ"
      },
      "source": [
        "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000,\n",
        "                     subtract_mean=True):\n",
        "    \"\"\"\n",
        "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
        "    it for classifiers. These are the same steps as we used for the SVM, but\n",
        "    condensed to a single function.\n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 data\n",
        "    train_data = CIFAR10('./CIFAR10', train=True, transform=transforms.ToTensor(), download=True)\n",
        "    test_data = CIFAR10('./CIFAR10', train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "    X_train, y_train = train_data.data.astype('float'), np.array(train_data.targets)\n",
        "    X_test, y_test = test_data.data.astype('float'), np.array(test_data.targets)\n",
        "\n",
        "    # Subsample the data\n",
        "    mask = list(range(num_training, num_training + num_validation))\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    mask = list(range(num_training))\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = list(range(num_test))\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "\n",
        "    # Normalize the data: subtract the mean image\n",
        "    if subtract_mean:\n",
        "        mean_image = np.mean(X_train, axis=0)\n",
        "        X_train -= mean_image\n",
        "        X_val -= mean_image\n",
        "        X_test -= mean_image\n",
        "\n",
        "    # Transpose so that channels come first\n",
        "    X_train = X_train.transpose(0, 3, 1, 2).copy()\n",
        "    X_val = X_val.transpose(0, 3, 1, 2).copy()\n",
        "    X_test = X_test.transpose(0, 3, 1, 2).copy()\n",
        "\n",
        "    # Package data into a dictionary\n",
        "    return {\n",
        "      'X_train': X_train, 'y_train': y_train,\n",
        "      'X_val': X_val, 'y_val': y_val,\n",
        "      'X_test': X_test, 'y_test': y_test,\n",
        "    }\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224,
          "referenced_widgets": [
            "193c90baf5554ad0a58ef7d6ef248d0a",
            "a5442f6331c745928fb68d43ae9f4ff1",
            "176fa6b1d3164536926800f5ff50f58a",
            "cdca0bb9d6d741f88090fb5fc87d892b",
            "bf6b7923426b46b396a9baf432637712",
            "b0d1798f57d14e1299813930562a6dc0",
            "0a8c31dabd494472b23a6c8746a523b2",
            "eac1a8ec449840ff8794e62534463d9d"
          ]
        },
        "id": "eLlvOkDkvww1",
        "outputId": "c9ad8857-6153-44f4-d2cb-881cb1f26619"
      },
      "source": [
        "# Load the (preprocessed) CIFAR10 data.\n",
        "\n",
        "data = get_CIFAR10_data()\n",
        "for k, v in list(data.items()):\n",
        "  print(('%s: ' % k, v.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./CIFAR10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "193c90baf5554ad0a58ef7d6ef248d0a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./CIFAR10/cifar-10-python.tar.gz to ./CIFAR10\n",
            "Files already downloaded and verified\n",
            "('X_train: ', (49000, 3, 32, 32))\n",
            "('y_train: ', (49000,))\n",
            "('X_val: ', (1000, 3, 32, 32))\n",
            "('y_val: ', (1000,))\n",
            "('X_test: ', (1000, 3, 32, 32))\n",
            "('y_test: ', (1000,))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lozjFkUL13Gf"
      },
      "source": [
        "def affine_forward(x, w, b):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for an affine (fully-connected) layer.\n",
        "\n",
        "    The input x has shape (N, d_1, ..., d_k) and contains a minibatch of N\n",
        "    examples, where each example x[i] has shape (d_1, ..., d_k). We will\n",
        "    reshape each input into a vector of dimension D = d_1 * ... * d_k, and\n",
        "    then transform it to an output vector of dimension M.\n",
        "\n",
        "    Inputs:\n",
        "    - x: A numpy array containing input data, of shape (N, d_1, ..., d_k)\n",
        "    - w: A numpy array of weights, of shape (D, M)\n",
        "    - b: A numpy array of biases, of shape (M,)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: output, of shape (N, M)\n",
        "    - cache: (x, w, b)\n",
        "    \"\"\"\n",
        "    out = None\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the affine forward pass. Store the result in out. You   #\n",
        "    # will need to reshape the input into rows.                               #\n",
        "    ###########################################################################\n",
        "    x=x.reshape(x.shape[0],-1)\n",
        "    out = x.dot(w)+b\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    cache = (x, w, b)\n",
        "    return out, cache\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP9Kjz4DwLQe",
        "outputId": "5d73908e-f2c7-4b3d-a1e8-a1cc8c6b2622"
      },
      "source": [
        "# Test the affine_forward function\n",
        "num_inputs = 2\n",
        "input_shape = (4, 5, 6)\n",
        "output_dim = 3\n",
        "\n",
        "input_size = num_inputs * np.prod(input_shape)\n",
        "weight_size = output_dim * np.prod(input_shape)\n",
        "\n",
        "x = np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape)\n",
        "w = np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_shape), output_dim)\n",
        "b = np.linspace(-0.3, 0.1, num=output_dim)\n",
        "\n",
        "out, _ = affine_forward(x, w, b)\n",
        "correct_out = np.array([[ 1.49834967,  1.70660132,  1.91485297],\n",
        "                        [ 3.25553199,  3.5141327,   3.77273342]])\n",
        "\n",
        "# Compare your output with ours. The error should be around 1e-9.\n",
        "print('Testing affine_forward function:')\n",
        "print('difference: ', rel_error(out, correct_out))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing affine_forward function:\n",
            "difference:  9.769849468192957e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsFzIULT464Z"
      },
      "source": [
        "def eval_numerical_gradient_array(f, x, df, h=1e-5):\n",
        "    \"\"\"\n",
        "    Evaluate a numeric gradient for a function that accepts a numpy\n",
        "    array and returns a numpy array.\n",
        "    \"\"\"\n",
        "    grad = np.zeros_like(x)\n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "        ix = it.multi_index\n",
        "\n",
        "        oldval = x[ix]\n",
        "        x[ix] = oldval + h\n",
        "        pos = f(x).copy()\n",
        "        x[ix] = oldval - h\n",
        "        neg = f(x).copy()\n",
        "        x[ix] = oldval\n",
        "\n",
        "        grad[ix] = np.sum((pos - neg) * df) / (2 * h)\n",
        "        it.iternext()\n",
        "    return grad"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrP3rlaM6KNU"
      },
      "source": [
        "def affine_backward(dout, cache):\n",
        "    \"\"\"\n",
        "    Computes the backward pass for an affine layer.\n",
        "\n",
        "    Inputs:\n",
        "    - dout: Upstream derivative, of shape (N, M)\n",
        "    - cache: Tuple of:\n",
        "      - x: Input data, of shape (N, d_1, ... d_k)\n",
        "      - w: Weights, of shape (D, M)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - dx: Gradient with respect to x, of shape (N, d1, ..., d_k)\n",
        "    - dw: Gradient with respect to w, of shape (D, M)\n",
        "    - db: Gradient with respect to b, of shape (M,)\n",
        "    \"\"\"\n",
        "    x, w, b = cache\n",
        "    dx, dw, db = None, None, None\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the affine backward pass.                               #\n",
        "    ###########################################################################\n",
        "  \n",
        "    dx = dout.dot(w.T)\n",
        "    dw = x.T.dot(dout)\n",
        "    db = dout.sum(axis=0)\n",
        "\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return dx, dw, db\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHLT_z5D4jOl",
        "outputId": "531c9d78-a4e5-402a-d94a-7bb7e30ca332"
      },
      "source": [
        "# Test the affine_backward function\n",
        "np.random.seed(231)\n",
        "x = np.random.randn(10, 2, 3)\n",
        "w = np.random.randn(6, 5)\n",
        "b = np.random.randn(5)\n",
        "dout = np.random.randn(10, 5)\n",
        "\n",
        "dx_num = eval_numerical_gradient_array(lambda x: affine_forward(x, w, b)[0], x, dout)\n",
        "dw_num = eval_numerical_gradient_array(lambda w: affine_forward(x, w, b)[0], w, dout)\n",
        "db_num = eval_numerical_gradient_array(lambda b: affine_forward(x, w, b)[0], b, dout)\n",
        "\n",
        "_, cache = affine_forward(x, w, b)\n",
        "dx, dw, db = affine_backward(dout, cache)\n",
        "dx = dx.reshape(dx_num.shape)\n",
        "# The error should be around 1e-10\n",
        "print('Testing affine_backward function:')\n",
        "print('dx error: ', rel_error(dx_num, dx))\n",
        "print('dw error: ', rel_error(dw_num, dw))\n",
        "print('db error: ', rel_error(db_num, db))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing affine_backward function:\n",
            "dx error:  5.399100368651805e-11\n",
            "dw error:  9.904211865398145e-11\n",
            "db error:  2.4122867568119087e-11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDVv7rY2QzLj"
      },
      "source": [
        "def relu_forward(x):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a layer of rectified linear units (ReLUs).\n",
        "\n",
        "    Input:\n",
        "    - x: Inputs, of any shape\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: Output, of the same shape as x\n",
        "    - cache: x\n",
        "    \"\"\"\n",
        "    out = None\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the ReLU forward pass.                                  #\n",
        "    ###########################################################################\n",
        "    out = np.maximum(0,x)\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    cache = x\n",
        "    return out, cache\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbUqIE_yR7fM"
      },
      "source": [
        "def relu_backward(dout, cache):\n",
        "    \"\"\"\n",
        "    Computes the backward pass for a layer of rectified linear units (ReLUs).\n",
        "\n",
        "    Input:\n",
        "    - dout: Upstream derivatives, of any shape\n",
        "    - cache: Input x, of same shape as dout\n",
        "\n",
        "    Returns:\n",
        "    - dx: Gradient with respect to x\n",
        "    \"\"\"\n",
        "    dx, x = None, cache\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the ReLU backward pass.                                 #\n",
        "    ###########################################################################\n",
        "    dx = dout\n",
        "    dx[x<=0] = 0\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return dx"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N71ErSfQieK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1230d31d-3086-4bd7-d77c-6c4d5a1a24e2"
      },
      "source": [
        "# Test the relu_forward function\n",
        "\n",
        "x = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)\n",
        "\n",
        "out, _ = relu_forward(x)\n",
        "correct_out = np.array([[ 0.,          0.,          0.,          0.,        ],\n",
        "                        [ 0.,          0.,          0.04545455,  0.13636364,],\n",
        "                        [ 0.22727273,  0.31818182,  0.40909091,  0.5,       ]])\n",
        "\n",
        "# Compare your output with ours. The error should be around 5e-8\n",
        "print('Testing relu_forward function:')\n",
        "print('difference: ', rel_error(out, correct_out))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing relu_forward function:\n",
            "difference:  4.999999798022158e-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T4XwSgiRfgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74a768d-2515-459a-80cd-7ee8c99ff01e"
      },
      "source": [
        "np.random.seed(231)\n",
        "x = np.random.randn(10, 10)\n",
        "dout = np.random.randn(*x.shape)\n",
        "\n",
        "dx_num = eval_numerical_gradient_array(lambda x: relu_forward(x)[0], x, dout)\n",
        "\n",
        "_, cache = relu_forward(x)\n",
        "dx = relu_backward(dout, cache)\n",
        "\n",
        "# The error should be around 3e-12\n",
        "print('Testing relu_backward function:')\n",
        "print('dx error: ', rel_error(dx_num, dx))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing relu_backward function:\n",
            "dx error:  3.2756349136310288e-12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLOYJAP-U1cT"
      },
      "source": [
        "def affine_relu_forward(x, w, b):\n",
        "    \"\"\"\n",
        "    Convenience layer that perorms an affine transform followed by a ReLU\n",
        "\n",
        "    Inputs:\n",
        "    - x: Input to the affine layer\n",
        "    - w, b: Weights for the affine layer\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: Output from the ReLU\n",
        "    - cache: Object to give to the backward pass\n",
        "    \"\"\"\n",
        "    a, fc_cache = affine_forward(x, w, b)\n",
        "    out, relu_cache = relu_forward(a)\n",
        "    cache = (fc_cache, relu_cache)\n",
        "    return out, cache\n",
        "\n",
        "\n",
        "def affine_relu_backward(dout, cache):\n",
        "    \"\"\"\n",
        "    Backward pass for the affine-relu convenience layer\n",
        "    \"\"\"\n",
        "    fc_cache, relu_cache = cache\n",
        "    da = relu_backward(dout, relu_cache)\n",
        "    dx, dw, db = affine_backward(da, fc_cache)\n",
        "    return dx, dw, db"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXkV5bBXTv8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8130c0b-0685-4553-e11e-40d96feeb99d"
      },
      "source": [
        "np.random.seed(231)\n",
        "x = np.random.randn(2, 3, 4)\n",
        "w = np.random.randn(12, 10)\n",
        "b = np.random.randn(10)\n",
        "dout = np.random.randn(2, 10)\n",
        "\n",
        "out, cache = affine_relu_forward(x, w, b)\n",
        "dx, dw, db = affine_relu_backward(dout, cache)\n",
        "\n",
        "dx_num = eval_numerical_gradient_array(lambda x: affine_relu_forward(x, w, b)[0], x, dout)\n",
        "dw_num = eval_numerical_gradient_array(lambda w: affine_relu_forward(x, w, b)[0], w, dout)\n",
        "db_num = eval_numerical_gradient_array(lambda b: affine_relu_forward(x, w, b)[0], b, dout)\n",
        "\n",
        "dx = dx.reshape(dx_num.shape)\n",
        "print('Testing affine_relu_forward:')\n",
        "print('dx error: ', rel_error(dx_num, dx))\n",
        "print('dw error: ', rel_error(dw_num, dw))\n",
        "print('db error: ', rel_error(db_num, db))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing affine_relu_forward:\n",
            "dx error:  2.299579177309368e-11\n",
            "dw error:  8.162011105764925e-11\n",
            "db error:  7.826724021458994e-12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGYTcjoUY2_k"
      },
      "source": [
        "def eval_numerical_gradient(f, x, verbose=True, h=0.00001):\n",
        "    \"\"\"\n",
        "    a naive implementation of numerical gradient of f at x\n",
        "    - f should be a function that takes a single argument\n",
        "    - x is the point (numpy array) to evaluate the gradient at\n",
        "    \"\"\"\n",
        "\n",
        "    fx = f(x) # evaluate function value at original point\n",
        "    grad = np.zeros_like(x)\n",
        "    # iterate over all indexes in x\n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "\n",
        "        # evaluate function at x+h\n",
        "        ix = it.multi_index\n",
        "        oldval = x[ix]\n",
        "        x[ix] = oldval + h # increment by h\n",
        "        fxph = f(x) # evalute f(x + h)\n",
        "        x[ix] = oldval - h\n",
        "        fxmh = f(x) # evaluate f(x - h)\n",
        "        x[ix] = oldval # restore\n",
        "\n",
        "        # compute the partial derivative with centered formula\n",
        "        grad[ix] = (fxph - fxmh) / (2 * h) # the slope\n",
        "        if verbose:\n",
        "            print(ix, grad[ix])\n",
        "        it.iternext() # step to next dimension\n",
        "\n",
        "    return grad"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBwMbOTuWhA6",
        "outputId": "cd449d14-3cef-4ff3-a657-01e8ebc73b23"
      },
      "source": [
        "np.random.seed(231)\n",
        "num_classes, num_inputs = 10, 50\n",
        "x = 0.001 * np.random.randn(num_inputs, num_classes)\n",
        "y = np.random.randint(num_classes, size=num_inputs)\n",
        "\n",
        "dx_num = eval_numerical_gradient(lambda x: svm_loss(x, y)[0], x, verbose=False)\n",
        "loss, dx = svm_loss(x, y)\n",
        "\n",
        "# Test svm_loss function. Loss should be around 9 and dx error should be 1e-9\n",
        "print('Testing svm_loss:')\n",
        "print('loss: ', loss)\n",
        "print('dx error: ', rel_error(dx_num, dx))\n",
        "\n",
        "dx_num = eval_numerical_gradient(lambda x: softmax_loss(x, y)[0], x, verbose=False)\n",
        "loss, dx = softmax_loss(x, y)\n",
        "\n",
        "# Test softmax_loss function. Loss should be 2.3 and dx error should be 1e-8\n",
        "print('\\nTesting softmax_loss:')\n",
        "print('loss: ', loss)\n",
        "print('dx error: ', rel_error(dx_num, dx))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing svm_loss:\n",
            "loss:  8.999602749096233\n",
            "dx error:  1.4021566006651672e-09\n",
            "\n",
            "Testing softmax_loss:\n",
            "loss:  2.302545844500738\n",
            "dx error:  9.384673161989355e-09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfQWzJB2bHgb"
      },
      "source": [
        "class TwoLayerNet(object):\n",
        "  \"\"\"\n",
        "  A two-layer fully-connected neural network with ReLU nonlinearity and\n",
        "  softmax loss that uses a modular layer design. We assume an input dimension\n",
        "  of D, a hidden dimension of H, and perform classification over C classes.\n",
        "\n",
        "  The architecure should be affine - relu - affine - softmax.\n",
        "\n",
        "  Note that this class does not implement gradient descent; instead, it\n",
        "  will interact with a separate Solver object that is responsible for running\n",
        "  optimization.\n",
        "\n",
        "  The learnable parameters of the model are stored in the dictionary\n",
        "  self.params that maps parameter names to numpy arrays.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, input_dim=3*32*32, hidden_dim=100, num_classes=10,\n",
        "                 weight_scale=1e-3, reg=0.0):\n",
        "    \"\"\"\n",
        "    Initialize a new network.\n",
        "\n",
        "    Inputs:\n",
        "    - input_dim: An integer giving the size of the input\n",
        "    - hidden_dim: An integer giving the size of the hidden layer\n",
        "    - num_classes: An integer giving the number of classes to classify\n",
        "    - dropout: Scalar between 0 and 1 giving dropout strength.\n",
        "    - weight_scale: Scalar giving the standard deviation for random\n",
        "      initialization of the weights.\n",
        "    - reg: Scalar giving L2 regularization strength.\n",
        "    \"\"\"\n",
        "    self.params = {}\n",
        "    self.reg = reg\n",
        "    self.params['W1'] = weight_scale*np.random.randn(input_dim,hidden_dim)\n",
        "    self.params['b1'] = np.zeros(hidden_dim)\n",
        "    self.params['W2'] = weight_scale*np.random.randn(hidden_dim,num_classes)\n",
        "    self.params['b2'] = np.zeros(num_classes)\n",
        "\n",
        "  def loss(self, X, y=None):\n",
        "    \"\"\"\n",
        "    Compute loss and gradient for a minibatch of data.\n",
        "\n",
        "    Inputs:\n",
        "    - X: Array of input data of shape (N, d_1, ..., d_k)\n",
        "    - y: Array of labels, of shape (N,). y[i] gives the label for X[i].\n",
        "\n",
        "    Returns:\n",
        "    If y is None, then run a test-time forward pass of the model and return:\n",
        "    - scores: Array of shape (N, C) giving classification scores, where\n",
        "      scores[i, c] is the classification score for X[i] and class c.\n",
        "\n",
        "    If y is not None, then run a training-time forward and backward pass and\n",
        "    return a tuple of:\n",
        "    - loss: Scalar value giving the loss\n",
        "    - grads: Dictionary with the same keys as self.params, mapping parameter\n",
        "      names to gradients of the loss with respect to those parameters.\n",
        "    \"\"\"\n",
        "    # Unpack variables from the params dictionary\n",
        "    W1, b1 = self.params['W1'], self.params['b1']\n",
        "    W2, b2 = self.params['W2'], self.params['b2']\n",
        "    dW1, dW2 = np.zeros_like(W1), np.zeros_like(W2)\n",
        "\n",
        "    # Compute the forward pass\n",
        "    scores = None\n",
        "    \n",
        "    ############################################################################\n",
        "    # TODO: Implement the forward pass for the two-layer net, computing the    #\n",
        "    # class scores for X and storing them in the scores variable.              #\n",
        "    ############################################################################\n",
        " \n",
        "    s1,l1_cache = affine_relu_forward(X,W1,b1)\n",
        "    scores,l2_cache = affine_forward(s1,W2,b2)\n",
        "    #############################################################################\n",
        "    #                              END OF YOUR CODE                             #\n",
        "    #############################################################################\n",
        "    \n",
        "    # If the targets are not given then jump out, we're done\n",
        "    if y is None:\n",
        "      return scores\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = None\n",
        "    #############################################################################\n",
        "    # TODO: Finish the forward pass, and compute the loss. This should include  #\n",
        "    # both the data loss and L2 regularization for W1 and W2. Store the result  #\n",
        "    # in the variable loss, which should be a scalar. Use the Softmax           #\n",
        "    # classifier loss.                                                          #\n",
        "    #############################################################################\n",
        "    loss,dout = softmax_loss(scores,y)\n",
        "    loss += (self.reg*np.sum(W2*W2) + self.reg*np.sum(W1*W1)) /2\n",
        "    \n",
        "    #############################################################################\n",
        "    #                              END OF YOUR CODE                             #\n",
        "    #############################################################################\n",
        "    \n",
        "    # Backward pass: compute gradients\n",
        "    grads = {}\n",
        "    #############################################################################\n",
        "    # TODO: Compute the backward pass, computing the derivatives of the weights #\n",
        "    # and biases. Store the results in the grads dictionary. For example,       #\n",
        "    # grads['W1'] should store the gradient on W1, and be a matrix of same size #\n",
        "    #############################################################################\n",
        "    \n",
        "    ds1,dW2,db2=affine_backward(dout,l2_cache)\n",
        "    _,dW1,db1 = affine_relu_backward(ds1,l1_cache)\n",
        "    \n",
        "    dW2+=self.reg*(W2)\n",
        "    dW1+=self.reg*(W1)\n",
        "\n",
        "    grads['W1'] = dW1\n",
        "    grads['W2'] = dW2\n",
        "    grads['b1'] = db1\n",
        "    grads['b2'] = db2\n",
        "    #############################################################################\n",
        "    #                              END OF YOUR CODE                             #\n",
        "    #############################################################################\n",
        "\n",
        "    return loss, grads\n",
        "\n",
        "  def train(self, X, y, X_val, y_val,\n",
        "            learning_rate=1e-3, learning_rate_decay=0.95,\n",
        "            reg=5e-6, num_iters=100,\n",
        "            batch_size=200, verbose=False):\n",
        "    \"\"\"\n",
        "    Train this neural network using stochastic gradient descent.\n",
        "\n",
        "    Inputs:\n",
        "    - X: A numpy array of shape (N, D) giving training data.\n",
        "    - y: A numpy array f shape (N,) giving training labels; y[i] = c means that\n",
        "      X[i] has label c, where 0 <= c < C.\n",
        "    - X_val: A numpy array of shape (N_val, D) giving validation data.\n",
        "    - y_val: A numpy array of shape (N_val,) giving validation labels.\n",
        "    - learning_rate: Scalar giving learning rate for optimization.\n",
        "    - learning_rate_decay: Scalar giving factor used to decay the learning rate\n",
        "      after each epoch.\n",
        "    - reg: Scalar giving regularization strength.\n",
        "    - num_iters: Number of steps to take when optimizing.\n",
        "    - batch_size: Number of training examples to use per step.\n",
        "    - verbose: boolean; if true print progress during optimization.\n",
        "    \"\"\"\n",
        "    num_train = X.shape[0]\n",
        "    iterations_per_epoch = max(num_train / batch_size, 1)\n",
        "\n",
        "    # Use SGD to optimize the parameters in self.model\n",
        "    loss_history = []\n",
        "    train_acc_history = []\n",
        "    val_acc_history = []\n",
        "\n",
        "    W1 , W2 = self.params['W1'], self.params['W2']\n",
        "    b1, b2 = self.params['b1'], self.params['b2']\n",
        "    for it in range(num_iters):\n",
        "      X_batch = None\n",
        "      y_batch = None\n",
        "\n",
        "      #########################################################################\n",
        "      # TODO: Create a random minibatch of training data and labels, storing  #\n",
        "      # them in X_batch and y_batch respectively.                             #\n",
        "      #########################################################################\n",
        "      mask = np.random.choice(range(num_train),batch_size)\n",
        "      X_batch = X[mask]\n",
        "      y_batch = y[mask]\n",
        "      #########################################################################\n",
        "      #                             END OF YOUR CODE                          #\n",
        "      #########################################################################\n",
        "\n",
        "      # Compute loss and gradients using the current minibatch\n",
        "      loss, grads = self.loss(X_batch, y=y_batch, reg=reg)\n",
        "      loss_history.append(loss)\n",
        "\n",
        "      #########################################################################\n",
        "      # TODO: Use the gradients in the grads dictionary to update the         #\n",
        "      # parameters of the network (stored in the dictionary self.params)      #\n",
        "      # using stochastic gradient descent. You'll need to use the gradients   #\n",
        "      # stored in the grads dictionary defined above.                         #\n",
        "      #########################################################################\n",
        "      W1-=learning_rate*grads['W1']\n",
        "      W2-= learning_rate * grads['W2']\n",
        "      b1-=learning_rate*grads['b1']\n",
        "      b2-=learning_rate*grads['b2']\n",
        "      #########################################################################\n",
        "      #                             END OF YOUR CODE                          #\n",
        "      #########################################################################\n",
        "\n",
        "      if verbose and it % 100 == 0:\n",
        "        print('iteration %d / %d: loss %f' % (it, num_iters, loss))\n",
        "\n",
        "      # Every epoch, check train and val accuracy and decay learning rate.\n",
        "      if it % iterations_per_epoch == 0:\n",
        "        # Check accuracy\n",
        "        train_acc = (self.predict(X_batch) == y_batch).mean()\n",
        "        val_acc = (self.predict(X_val) == y_val).mean()\n",
        "        train_acc_history.append(train_acc)\n",
        "        val_acc_history.append(val_acc)\n",
        "\n",
        "        # Decay learning rate\n",
        "        learning_rate *= learning_rate_decay\n",
        "\n",
        "    self.params['W1'], self.params['W2'] = W1,W2\n",
        "    self.params['b1'], self.params['b2'] = b1, b2\n",
        "    return {\n",
        "      'loss_history': loss_history,\n",
        "      'train_acc_history': train_acc_history,\n",
        "      'val_acc_history': val_acc_history,\n",
        "    }\n",
        "\n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    Use the trained weights of this two-layer network to predict labels for\n",
        "    data points. For each data point we predict scores for each of the C\n",
        "    classes, and assign each data point to the class with the highest score.\n",
        "\n",
        "    Inputs:\n",
        "    - X: A numpy array of shape (N, D) giving N D-dimensional data points to\n",
        "      classify.\n",
        "\n",
        "    Returns:\n",
        "    - y_pred: A numpy array of shape (N,) giving predicted labels for each of\n",
        "      the elements of X. For all i, y_pred[i] = c means that X[i] is predicted\n",
        "      to have class c, where 0 <= c < C.\n",
        "    \"\"\"\n",
        "    y_pred = None\n",
        "\n",
        "    ###########################################################################\n",
        "    # TODO: Implement this function; it should be VERY simple!                #\n",
        "    ###########################################################################\n",
        "    W1, W2 = self.params['W1'], self.params['W2']\n",
        "    b1, b2 = self.params['b1'], self.params['b2']\n",
        "\n",
        "    s1=X.dot(W1) + b1\n",
        "    s2=s1.dot(W2) + b2\n",
        "\n",
        "    scores = np.exp(s2) / np.expand_dims(np.exp(s2).sum(axis=1),1)\n",
        "\n",
        "    y_pred = scores.argmax(axis=1)\n",
        "    ###########################################################################\n",
        "    #                              END OF YOUR CODE                           #\n",
        "    ###########################################################################\n",
        "\n",
        "    return y_pred\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqM_OSgcZ1Dy",
        "outputId": "c8e28747-4cf4-4769-e8fe-c037c48a91d9"
      },
      "source": [
        "np.random.seed(231)\n",
        "N, D, H, C = 3, 5, 50, 7\n",
        "X = np.random.randn(N, D)\n",
        "y = np.random.randint(C, size=N)\n",
        "\n",
        "std = 1e-3\n",
        "model = TwoLayerNet(input_dim=D, hidden_dim=H, num_classes=C, weight_scale=std)\n",
        "\n",
        "print('Testing initialization ... ')\n",
        "W1_std = abs(model.params['W1'].std() - std)\n",
        "b1 = model.params['b1']\n",
        "W2_std = abs(model.params['W2'].std() - std)\n",
        "b2 = model.params['b2']\n",
        "assert W1_std < std / 10, 'First layer weights do not seem right'\n",
        "assert np.all(b1 == 0), 'First layer biases do not seem right'\n",
        "assert W2_std < std / 10, 'Second layer weights do not seem right'\n",
        "assert np.all(b2 == 0), 'Second layer biases do not seem right'\n",
        "\n",
        "print('Testing test-time forward pass ... ')\n",
        "model.params['W1'] = np.linspace(-0.7, 0.3, num=D*H).reshape(D, H)\n",
        "model.params['b1'] = np.linspace(-0.1, 0.9, num=H)\n",
        "model.params['W2'] = np.linspace(-0.3, 0.4, num=H*C).reshape(H, C)\n",
        "model.params['b2'] = np.linspace(-0.9, 0.1, num=C)\n",
        "X = np.linspace(-5.5, 4.5, num=N*D).reshape(D, N).T\n",
        "scores = model.loss(X)\n",
        "correct_scores = np.asarray(\n",
        "  [[11.53165108,  12.2917344,   13.05181771,  13.81190102,  14.57198434, 15.33206765,  16.09215096],\n",
        "   [12.05769098,  12.74614105,  13.43459113,  14.1230412,   14.81149128, 15.49994135,  16.18839143],\n",
        "   [12.58373087,  13.20054771,  13.81736455,  14.43418138,  15.05099822, 15.66781506,  16.2846319 ]])\n",
        "scores_diff = np.abs(scores - correct_scores).sum()\n",
        "assert scores_diff < 1e-6, 'Problem with test-time forward pass'\n",
        "\n",
        "print('Testing training loss (no regularization)')\n",
        "y = np.asarray([0, 5, 1])\n",
        "loss, grads = model.loss(X, y)\n",
        "correct_loss = 3.4702243556\n",
        "\n",
        "assert abs(loss - correct_loss) < 1e-10, 'Problem with training-time loss'\n",
        "\n",
        "model.reg = 1.0\n",
        "loss, grads = model.loss(X, y)\n",
        "correct_loss = 26.5948426952\n",
        "assert abs(loss - correct_loss) < 1e-10, 'Problem with regularization loss'\n",
        "\n",
        "for reg in [0.0, 0.7]:\n",
        "  print('Running numeric gradient check with reg = ', reg)\n",
        "  model.reg = reg\n",
        "  loss, grads = model.loss(X, y)\n",
        "\n",
        "  for name in sorted(grads):\n",
        "    f = lambda _: model.loss(X, y)[0]\n",
        "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False)\n",
        "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing initialization ... \n",
            "Testing test-time forward pass ... \n",
            "Testing training loss (no regularization)\n",
            "Running numeric gradient check with reg =  0.0\n",
            "W1 relative error: 1.83e-08\n",
            "W2 relative error: 3.12e-10\n",
            "b1 relative error: 9.83e-09\n",
            "b2 relative error: 4.33e-10\n",
            "Running numeric gradient check with reg =  0.7\n",
            "W1 relative error: 2.53e-07\n",
            "W2 relative error: 7.98e-08\n",
            "b1 relative error: 1.56e-08\n",
            "b2 relative error: 7.76e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBoqmzxsXbqV"
      },
      "source": [
        "class Solver(object):\n",
        "    \"\"\"\n",
        "    A Solver encapsulates all the logic necessary for training classification\n",
        "    models. The Solver performs stochastic gradient descent using different\n",
        "    update rules defined in optim.py.\n",
        "\n",
        "    The solver accepts both training and validataion data and labels so it can\n",
        "    periodically check classification accuracy on both training and validation\n",
        "    data to watch out for overfitting.\n",
        "\n",
        "    To train a model, you will first construct a Solver instance, passing the\n",
        "    model, dataset, and various optoins (learning rate, batch size, etc) to the\n",
        "    constructor. You will then call the train() method to run the optimization\n",
        "    procedure and train the model.\n",
        "\n",
        "    After the train() method returns, model.params will contain the parameters\n",
        "    that performed best on the validation set over the course of training.\n",
        "    In addition, the instance variable solver.loss_history will contain a list\n",
        "    of all losses encountered during training and the instance variables\n",
        "    solver.train_acc_history and solver.val_acc_history will be lists of the\n",
        "    accuracies of the model on the training and validation set at each epoch.\n",
        "\n",
        "    Example usage might look something like this:\n",
        "\n",
        "    data = {\n",
        "      'X_train': # training data\n",
        "      'y_train': # training labels\n",
        "      'X_val': # validation data\n",
        "      'y_val': # validation labels\n",
        "    }\n",
        "    model = MyAwesomeModel(hidden_size=100, reg=10)\n",
        "    solver = Solver(model, data,\n",
        "                    update_rule='sgd',\n",
        "                    optim_config={\n",
        "                      'learning_rate': 1e-3,\n",
        "                    },\n",
        "                    lr_decay=0.95,\n",
        "                    num_epochs=10, batch_size=100,\n",
        "                    print_every=100)\n",
        "    solver.train()\n",
        "\n",
        "\n",
        "    A Solver works on a model object that must conform to the following API:\n",
        "\n",
        "    - model.params must be a dictionary mapping string parameter names to numpy\n",
        "      arrays containing parameter values.\n",
        "\n",
        "    - model.loss(X, y) must be a function that computes training-time loss and\n",
        "      gradients, and test-time classification scores, with the following inputs\n",
        "      and outputs:\n",
        "\n",
        "      Inputs:\n",
        "      - X: Array giving a minibatch of input data of shape (N, d_1, ..., d_k)\n",
        "      - y: Array of labels, of shape (N,) giving labels for X where y[i] is the\n",
        "        label for X[i].\n",
        "\n",
        "      Returns:\n",
        "      If y is None, run a test-time forward pass and return:\n",
        "      - scores: Array of shape (N, C) giving classification scores for X where\n",
        "        scores[i, c] gives the score of class c for X[i].\n",
        "\n",
        "      If y is not None, run a training time forward and backward pass and\n",
        "      return a tuple of:\n",
        "      - loss: Scalar giving the loss\n",
        "      - grads: Dictionary with the same keys as self.params mapping parameter\n",
        "        names to gradients of the loss with respect to those parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, data, **kwargs):\n",
        "        \"\"\"\n",
        "        Construct a new Solver instance.\n",
        "\n",
        "        Required arguments:\n",
        "        - model: A model object conforming to the API described above\n",
        "        - data: A dictionary of training and validation data containing:\n",
        "          'X_train': Array, shape (N_train, d_1, ..., d_k) of training images\n",
        "          'X_val': Array, shape (N_val, d_1, ..., d_k) of validation images\n",
        "          'y_train': Array, shape (N_train,) of labels for training images\n",
        "          'y_val': Array, shape (N_val,) of labels for validation images\n",
        "\n",
        "        Optional arguments:\n",
        "        - update_rule: A string giving the name of an update rule in optim.py.\n",
        "          Default is 'sgd'.\n",
        "        - optim_config: A dictionary containing hyperparameters that will be\n",
        "          passed to the chosen update rule. Each update rule requires different\n",
        "          hyperparameters (see optim.py) but all update rules require a\n",
        "          'learning_rate' parameter so that should always be present.\n",
        "        - lr_decay: A scalar for learning rate decay; after each epoch the\n",
        "          learning rate is multiplied by this value.\n",
        "        - batch_size: Size of minibatches used to compute loss and gradient\n",
        "          during training.\n",
        "        - num_epochs: The number of epochs to run for during training.\n",
        "        - print_every: Integer; training losses will be printed every\n",
        "          print_every iterations.\n",
        "        - verbose: Boolean; if set to false then no output will be printed\n",
        "          during training.\n",
        "        - num_train_samples: Number of training samples used to check training\n",
        "          accuracy; default is 1000; set to None to use entire training set.\n",
        "        - num_val_samples: Number of validation samples to use to check val\n",
        "          accuracy; default is None, which uses the entire validation set.\n",
        "        - checkpoint_name: If not None, then save model checkpoints here every\n",
        "          epoch.\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.X_train = data['X_train']\n",
        "        self.y_train = data['y_train']\n",
        "        self.X_val = data['X_val']\n",
        "        self.y_val = data['y_val']\n",
        "\n",
        "        # Unpack keyword arguments\n",
        "        self.update_rule = kwargs.pop('update_rule', 'sgd')\n",
        "        self.optim_config = kwargs.pop('optim_config', {})\n",
        "        self.lr_decay = kwargs.pop('lr_decay', 1.0)\n",
        "        self.batch_size = kwargs.pop('batch_size', 100)\n",
        "        self.num_epochs = kwargs.pop('num_epochs', 10)\n",
        "        self.num_train_samples = kwargs.pop('num_train_samples', 1000)\n",
        "        self.num_val_samples = kwargs.pop('num_val_samples', None)\n",
        "\n",
        "        self.checkpoint_name = kwargs.pop('checkpoint_name', None)\n",
        "        self.print_every = kwargs.pop('print_every', 10)\n",
        "        self.verbose = kwargs.pop('verbose', True)\n",
        "\n",
        "        # Throw an error if there are extra keyword arguments\n",
        "        if len(kwargs) > 0:\n",
        "            extra = ', '.join('\"%s\"' % k for k in list(kwargs.keys()))\n",
        "            raise ValueError('Unrecognized arguments %s' % extra)\n",
        "\n",
        "        # Make sure the update rule exists, then replace the string\n",
        "        # name with the actual function\n",
        "        if not hasattr(optim, self.update_rule):\n",
        "            raise ValueError('Invalid update_rule \"%s\"' % self.update_rule)\n",
        "        self.update_rule = getattr(optim, self.update_rule)\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "\n",
        "    def _reset(self):\n",
        "        \"\"\"\n",
        "        Set up some book-keeping variables for optimization. Don't call this\n",
        "        manually.\n",
        "        \"\"\"\n",
        "        # Set up some variables for book-keeping\n",
        "        self.epoch = 0\n",
        "        self.best_val_acc = 0\n",
        "        self.best_params = {}\n",
        "        self.loss_history = []\n",
        "        self.train_acc_history = []\n",
        "        self.val_acc_history = []\n",
        "\n",
        "        # Make a deep copy of the optim_config for each parameter\n",
        "        self.optim_configs = {}\n",
        "        for p in self.model.params:\n",
        "            d = {k: v for k, v in self.optim_config.items()}\n",
        "            self.optim_configs[p] = d\n",
        "\n",
        "\n",
        "    def _step(self):\n",
        "        \"\"\"\n",
        "        Make a single gradient update. This is called by train() and should not\n",
        "        be called manually.\n",
        "        \"\"\"\n",
        "        # Make a minibatch of training data\n",
        "        num_train = self.X_train.shape[0]\n",
        "        batch_mask = np.random.choice(num_train, self.batch_size)\n",
        "        X_batch = self.X_train[batch_mask]\n",
        "        y_batch = self.y_train[batch_mask]\n",
        "\n",
        "        # Compute loss and gradient\n",
        "        loss, grads = self.model.loss(X_batch, y_batch)\n",
        "        self.loss_history.append(loss)\n",
        "\n",
        "        # Perform a parameter update\n",
        "        for p, w in self.model.params.items():\n",
        "            dw = grads[p]\n",
        "            config = self.optim_configs[p]\n",
        "            next_w, next_config = self.update_rule(w, dw, config)\n",
        "            self.model.params[p] = next_w\n",
        "            self.optim_configs[p] = next_config\n",
        "\n",
        "\n",
        "    def _save_checkpoint(self):\n",
        "        if self.checkpoint_name is None: return\n",
        "        checkpoint = {\n",
        "          'model': self.model,\n",
        "          'update_rule': self.update_rule,\n",
        "          'lr_decay': self.lr_decay,\n",
        "          'optim_config': self.optim_config,\n",
        "          'batch_size': self.batch_size,\n",
        "          'num_train_samples': self.num_train_samples,\n",
        "          'num_val_samples': self.num_val_samples,\n",
        "          'epoch': self.epoch,\n",
        "          'loss_history': self.loss_history,\n",
        "          'train_acc_history': self.train_acc_history,\n",
        "          'val_acc_history': self.val_acc_history,\n",
        "        }\n",
        "        filename = '%s_epoch_%d.pkl' % (self.checkpoint_name, self.epoch)\n",
        "        if self.verbose:\n",
        "            print('Saving checkpoint to \"%s\"' % filename)\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(checkpoint, f)\n",
        "\n",
        "\n",
        "    def check_accuracy(self, X, y, num_samples=None, batch_size=100):\n",
        "        \"\"\"\n",
        "        Check accuracy of the model on the provided data.\n",
        "\n",
        "        Inputs:\n",
        "        - X: Array of data, of shape (N, d_1, ..., d_k)\n",
        "        - y: Array of labels, of shape (N,)\n",
        "        - num_samples: If not None, subsample the data and only test the model\n",
        "          on num_samples datapoints.\n",
        "        - batch_size: Split X and y into batches of this size to avoid using\n",
        "          too much memory.\n",
        "\n",
        "        Returns:\n",
        "        - acc: Scalar giving the fraction of instances that were correctly\n",
        "          classified by the model.\n",
        "        \"\"\"\n",
        "\n",
        "        # Maybe subsample the data\n",
        "        N = X.shape[0]\n",
        "        if num_samples is not None and N > num_samples:\n",
        "            mask = np.random.choice(N, num_samples)\n",
        "            N = num_samples\n",
        "            X = X[mask]\n",
        "            y = y[mask]\n",
        "\n",
        "        # Compute predictions in batches\n",
        "        num_batches = N // batch_size\n",
        "        if N % batch_size != 0:\n",
        "            num_batches += 1\n",
        "        y_pred = []\n",
        "        for i in range(num_batches):\n",
        "            start = i * batch_size\n",
        "            end = (i + 1) * batch_size\n",
        "            scores = self.model.loss(X[start:end])\n",
        "            y_pred.append(np.argmax(scores, axis=1))\n",
        "        y_pred = np.hstack(y_pred)\n",
        "        acc = np.mean(y_pred == y)\n",
        "\n",
        "        return acc\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Run optimization to train the model.\n",
        "        \"\"\"\n",
        "        num_train = self.X_train.shape[0]\n",
        "        iterations_per_epoch = max(num_train // self.batch_size, 1)\n",
        "        num_iterations = self.num_epochs * iterations_per_epoch\n",
        "\n",
        "        for t in range(num_iterations):\n",
        "            self._step()\n",
        "\n",
        "            # Maybe print training loss\n",
        "            if self.verbose and t % self.print_every == 0:\n",
        "                print('(Iteration %d / %d) loss: %f' % (\n",
        "                       t + 1, num_iterations, self.loss_history[-1]))\n",
        "\n",
        "            # At the end of every epoch, increment the epoch counter and decay\n",
        "            # the learning rate.\n",
        "            epoch_end = (t + 1) % iterations_per_epoch == 0\n",
        "            if epoch_end:\n",
        "                self.epoch += 1\n",
        "                for k in self.optim_configs:\n",
        "                    self.optim_configs[k]['learning_rate'] *= self.lr_decay\n",
        "\n",
        "            # Check train and val accuracy on the first iteration, the last\n",
        "            # iteration, and at the end of each epoch.\n",
        "            first_it = (t == 0)\n",
        "            last_it = (t == num_iterations - 1)\n",
        "            if first_it or last_it or epoch_end:\n",
        "                train_acc = self.check_accuracy(self.X_train, self.y_train,\n",
        "                    num_samples=self.num_train_samples)\n",
        "                val_acc = self.check_accuracy(self.X_val, self.y_val,\n",
        "                    num_samples=self.num_val_samples)\n",
        "                self.train_acc_history.append(train_acc)\n",
        "                self.val_acc_history.append(val_acc)\n",
        "                self._save_checkpoint()\n",
        "\n",
        "                if self.verbose:\n",
        "                    print('(Epoch %d / %d) train acc: %f; val_acc: %f' % (\n",
        "                           self.epoch, self.num_epochs, train_acc, val_acc))\n",
        "\n",
        "                # Keep track of the best model\n",
        "                if val_acc > self.best_val_acc:\n",
        "                    self.best_val_acc = val_acc\n",
        "                    self.best_params = {}\n",
        "                    for k, v in self.model.params.items():\n",
        "                        self.best_params[k] = v.copy()\n",
        "\n",
        "        # At the end of training swap the best params into the model\n",
        "        self.model.params = self.best_params\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDjGIbj8WGsC",
        "outputId": "ffc48d97-29b7-4ae3-c23d-5db6e7a4c86b"
      },
      "source": [
        "model = TwoLayerNet()\n",
        "solver = None\n",
        "\n",
        "##############################################################################\n",
        "# TODO: Use a Solver instance to train a TwoLayerNet that achieves at least  #\n",
        "# 50% accuracy on the validation set.                                        #\n",
        "##############################################################################\n",
        "solver = Solver(model, data,\n",
        "                    update_rule='sgd',\n",
        "                    optim_config={\n",
        "                      'learning_rate': 1e-3,\n",
        "                    },\n",
        "                    lr_decay=0.95,\n",
        "                    num_epochs=10, batch_size=100,\n",
        "                    print_every=100)\n",
        "print(data['X_train'].shape)\n",
        "solver.train()\n",
        "##############################################################################\n",
        "#                             END OF YOUR CODE                               #\n",
        "##############################################################################"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49000, 3, 32, 32)\n",
            "(Iteration 1 / 4900) loss: 2.304060\n",
            "(Epoch 0 / 10) train acc: 0.116000; val_acc: 0.094000\n",
            "(Iteration 101 / 4900) loss: 1.829613\n",
            "(Iteration 201 / 4900) loss: 1.857390\n",
            "(Iteration 301 / 4900) loss: 1.744448\n",
            "(Iteration 401 / 4900) loss: 1.420187\n",
            "(Epoch 1 / 10) train acc: 0.407000; val_acc: 0.422000\n",
            "(Iteration 501 / 4900) loss: 1.565913\n",
            "(Iteration 601 / 4900) loss: 1.700510\n",
            "(Iteration 701 / 4900) loss: 1.732213\n",
            "(Iteration 801 / 4900) loss: 1.688361\n",
            "(Iteration 901 / 4900) loss: 1.439529\n",
            "(Epoch 2 / 10) train acc: 0.497000; val_acc: 0.468000\n",
            "(Iteration 1001 / 4900) loss: 1.385772\n",
            "(Iteration 1101 / 4900) loss: 1.278401\n",
            "(Iteration 1201 / 4900) loss: 1.641580\n",
            "(Iteration 1301 / 4900) loss: 1.438847\n",
            "(Iteration 1401 / 4900) loss: 1.172536\n",
            "(Epoch 3 / 10) train acc: 0.490000; val_acc: 0.466000\n",
            "(Iteration 1501 / 4900) loss: 1.346286\n",
            "(Iteration 1601 / 4900) loss: 1.268492\n",
            "(Iteration 1701 / 4900) loss: 1.318215\n",
            "(Iteration 1801 / 4900) loss: 1.395750\n",
            "(Iteration 1901 / 4900) loss: 1.338233\n",
            "(Epoch 4 / 10) train acc: 0.532000; val_acc: 0.497000\n",
            "(Iteration 2001 / 4900) loss: 1.343165\n",
            "(Iteration 2101 / 4900) loss: 1.393173\n",
            "(Iteration 2201 / 4900) loss: 1.276734\n",
            "(Iteration 2301 / 4900) loss: 1.287951\n",
            "(Iteration 2401 / 4900) loss: 1.352778\n",
            "(Epoch 5 / 10) train acc: 0.525000; val_acc: 0.475000\n",
            "(Iteration 2501 / 4900) loss: 1.390234\n",
            "(Iteration 2601 / 4900) loss: 1.276361\n",
            "(Iteration 2701 / 4900) loss: 1.111768\n",
            "(Iteration 2801 / 4900) loss: 1.271688\n",
            "(Iteration 2901 / 4900) loss: 1.272039\n",
            "(Epoch 6 / 10) train acc: 0.546000; val_acc: 0.509000\n",
            "(Iteration 3001 / 4900) loss: 1.304489\n",
            "(Iteration 3101 / 4900) loss: 1.346667\n",
            "(Iteration 3201 / 4900) loss: 1.325510\n",
            "(Iteration 3301 / 4900) loss: 1.392728\n",
            "(Iteration 3401 / 4900) loss: 1.402001\n",
            "(Epoch 7 / 10) train acc: 0.567000; val_acc: 0.505000\n",
            "(Iteration 3501 / 4900) loss: 1.319024\n",
            "(Iteration 3601 / 4900) loss: 1.153287\n",
            "(Iteration 3701 / 4900) loss: 1.180922\n",
            "(Iteration 3801 / 4900) loss: 1.093164\n",
            "(Iteration 3901 / 4900) loss: 1.135902\n",
            "(Epoch 8 / 10) train acc: 0.568000; val_acc: 0.490000\n",
            "(Iteration 4001 / 4900) loss: 1.191735\n",
            "(Iteration 4101 / 4900) loss: 1.359396\n",
            "(Iteration 4201 / 4900) loss: 1.227283\n",
            "(Iteration 4301 / 4900) loss: 1.024113\n",
            "(Iteration 4401 / 4900) loss: 1.327583\n",
            "(Epoch 9 / 10) train acc: 0.592000; val_acc: 0.504000\n",
            "(Iteration 4501 / 4900) loss: 0.963330\n",
            "(Iteration 4601 / 4900) loss: 1.445619\n",
            "(Iteration 4701 / 4900) loss: 1.007542\n",
            "(Iteration 4801 / 4900) loss: 1.005175\n",
            "(Epoch 10 / 10) train acc: 0.611000; val_acc: 0.512000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "v8VlpahxXqOI",
        "outputId": "4e5c5343-0f24-41f0-e5c3-5a9c74f04d04"
      },
      "source": [
        "# Run this cell to visualize training loss and train / val accuracy\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.title('Training loss')\n",
        "plt.plot(solver.loss_history, 'o')\n",
        "plt.xlabel('Iteration')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.title('Accuracy')\n",
        "plt.plot(solver.train_acc_history, '-o', label='train')\n",
        "plt.plot(solver.val_acc_history, '-o', label='val')\n",
        "plt.plot([0.5] * len(solver.val_acc_history), 'k--')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='lower right')\n",
        "plt.gcf().set_size_inches(15, 12)\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7YKNoz_Zdi8"
      },
      "source": [
        "class FullyConnectedNet(object):\n",
        "    \"\"\"\n",
        "    A fully-connected neural network with an arbitrary number of hidden layers,\n",
        "    ReLU nonlinearities, and a softmax loss function. This will also implement\n",
        "    dropout and batch normalization as options. For a network with L layers,\n",
        "    the architecture will be\n",
        "\n",
        "    {affine - [batch norm] - relu - [dropout]} x (L - 1) - affine - softmax\n",
        "\n",
        "    where batch normalization and dropout are optional, and the {...} block is\n",
        "    repeated L - 1 times.\n",
        "\n",
        "    Similar to the TwoLayerNet above, learnable parameters are stored in the\n",
        "    self.params dictionary and will be learned using the Solver class.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_dims, input_dim=3*32*32, num_classes=10,\n",
        "                 dropout=0, use_batchnorm=False, reg=0.0,\n",
        "                 weight_scale=1e-2, dtype=np.float32, seed=None):\n",
        "        \"\"\"\n",
        "        Initialize a new FullyConnectedNet.\n",
        "\n",
        "        Inputs:\n",
        "        - hidden_dims: A list of integers giving the size of each hidden layer.\n",
        "        - input_dim: An integer giving the size of the input.\n",
        "        - num_classes: An integer giving the number of classes to classify.\n",
        "        - dropout: Scalar between 0 and 1 giving dropout strength. If dropout=0 then\n",
        "          the network should not use dropout at all.\n",
        "        - use_batchnorm: Whether or not the network should use batch normalization.\n",
        "        - reg: Scalar giving L2 regularization strength.\n",
        "        - weight_scale: Scalar giving the standard deviation for random\n",
        "          initialization of the weights.\n",
        "        - dtype: A numpy datatype object; all computations will be performed using\n",
        "          this datatype. float32 is faster but less accurate, so you should use\n",
        "          float64 for numeric gradient checking.\n",
        "        - seed: If not None, then pass this random seed to the dropout layers. This\n",
        "          will make the dropout layers deteriminstic so we can gradient check the\n",
        "          model.\n",
        "        \"\"\"\n",
        "        self.use_batchnorm = use_batchnorm\n",
        "        self.use_dropout = dropout > 0\n",
        "        self.reg = reg\n",
        "        self.num_layers = 1 + len(hidden_dims)\n",
        "        self.dtype = dtype\n",
        "        self.params = {}\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Initialize the parameters of the network, storing all values in    #\n",
        "        # the self.params dictionary. Store weights and biases for the first layer #\n",
        "        # in W1 and b1; for the second layer use W2 and b2, etc. Weights should be #\n",
        "        # initialized from a normal distribution with standard deviation equal to  #\n",
        "        # weight_scale and biases should be initialized to zero.                   #\n",
        "        #                                                                          #\n",
        "        # When using batch normalization, store scale and shift parameters for the #\n",
        "        # first layer in gamma1 and beta1; for the second layer use gamma2 and     #\n",
        "        # beta2, etc. Scale parameters should be initialized to one and shift      #\n",
        "        # parameters should be initialized to zero.                                #\n",
        "        ############################################################################\n",
        "        prev_hidden_dim = None\n",
        "        \n",
        "        for i in range(self.num_layers):\n",
        "          \n",
        "          if i== self.num_layers-1:\n",
        "            w = np.random.randn(prev_hidden_dim,num_classes) * weight_scale\n",
        "            b = np.zeros((num_classes,))\n",
        "          else:\n",
        "            hidden_dim = hidden_dims[i]\n",
        "            b = np.zeros((hidden_dim,))\n",
        "\n",
        "            if i == 0:\n",
        "              w = np.random.randn(input_dim, hidden_dim) * weight_scale\n",
        "            else:\n",
        "              w = np.random.randn(prev_hidden_dim, hidden_dim) * weight_scale\n",
        "          \n",
        "            \n",
        "          \n",
        "          prev_hidden_dim = hidden_dim\n",
        "          w_params_name = 'w'+str(i+1)\n",
        "          b_params_name = 'b'+str(i+1)\n",
        "          self.params[w_params_name] = w\n",
        "          self.params[b_params_name] = b\n",
        "\n",
        "        ############################################################################\n",
        "        #                             END OF YOUR CODE                             #\n",
        "        ############################################################################\n",
        "\n",
        "        # When using dropout we need to pass a dropout_param dictionary to each\n",
        "        # dropout layer so that the layer knows the dropout probability and the mode\n",
        "        # (train / test). You can pass the same dropout_param to each dropout layer.\n",
        "        self.dropout_param = {}\n",
        "        if self.use_dropout:\n",
        "            self.dropout_param = {'mode': 'train', 'p': dropout}\n",
        "            if seed is not None:\n",
        "                self.dropout_param['seed'] = seed\n",
        "\n",
        "        # With batch normalization we need to keep track of running means and\n",
        "        # variances, so we need to pass a special bn_param object to each batch\n",
        "        # normalization layer. You should pass self.bn_params[0] to the forward pass\n",
        "        # of the first batch normalization layer, self.bn_params[1] to the forward\n",
        "        # pass of the second batch normalization layer, etc.\n",
        "        self.bn_params = []\n",
        "        if self.use_batchnorm:\n",
        "            self.bn_params = [{'mode': 'train'} for i in range(self.num_layers - 1)]\n",
        "\n",
        "        # Cast all parameters to the correct datatype\n",
        "        for k, v in self.params.items():\n",
        "            self.params[k] = v.astype(dtype)\n",
        "\n",
        "\n",
        "    def loss(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Compute loss and gradient for the fully-connected net.\n",
        "\n",
        "        Input / output: Same as TwoLayerNet above.\n",
        "        \"\"\"\n",
        "        X = X.astype(self.dtype)\n",
        "        mode = 'test' if y is None else 'train'\n",
        "\n",
        "        # Set train/test mode for batchnorm params and dropout param since they\n",
        "        # behave differently during training and testing.\n",
        "        if self.use_dropout:\n",
        "            self.dropout_param['mode'] = mode\n",
        "        if self.use_batchnorm:\n",
        "            for bn_param in self.bn_params:\n",
        "                bn_param['mode'] = mode\n",
        "\n",
        "        scores = None\n",
        "        ############################################################################\n",
        "        # TODO: Implement the forward pass for the fully-connected net, computing  #\n",
        "        # the class scores for X and storing them in the scores variable.          #\n",
        "        #                                                                          #\n",
        "        # When using dropout, you'll need to pass self.dropout_param to each       #\n",
        "        # dropout forward pass.                                                    #\n",
        "        #                                                                          #\n",
        "        # When using batch normalization, you'll need to pass self.bn_params[0] to #\n",
        "        # the forward pass for the first batch normalization layer, pass           #\n",
        "        # self.bn_params[1] to the forward pass for the second batch normalization #\n",
        "        # layer, etc.                                                              #\n",
        "        ############################################################################\n",
        "        cache_list = []\n",
        "        for i in range(self.num_layers):\n",
        "            w = self.params['w'+str(i+1)]\n",
        "            b = self.params['b'+str(i+1)]\n",
        "            \n",
        "            if i ==0:\n",
        "              out,cache = affine_relu_forward(X,w,b)\n",
        "            elif i == self.num_layers -1:\n",
        "              scores,cache = affine_forward(out,w,b)\n",
        "            else:\n",
        "              out,cache = affine_relu_forward(out,w,b)\n",
        "\n",
        "            cache_list.append(cache)      \n",
        "        ############################################################################\n",
        "        #                             END OF YOUR CODE                             #\n",
        "        ############################################################################\n",
        "\n",
        "        # If test mode return early\n",
        "        if mode == 'test' or y is None:\n",
        "            return scores\n",
        "\n",
        "        loss, grads = 0.0, {}\n",
        "        ############################################################################\n",
        "        # TODO: Implement the backward pass for the fully-connected net. Store the #\n",
        "        # loss in the loss variable and gradients in the grads dictionary. Compute #\n",
        "        # data loss using softmax, and make sure that grads[k] holds the gradients #\n",
        "        # for self.params[k]. Don't forget to add L2 regularization!               #\n",
        "        #                                                                          #\n",
        "        # When using batch normalization, you don't need to regularize the scale   #\n",
        "        # and shift parameters.                                                    #\n",
        "        #                                                                          #\n",
        "        # NOTE: To ensure that your implementation matches ours and you pass the   #\n",
        "        # automated tests, make sure that your L2 regularization includes a factor #\n",
        "        # of 0.5 to simplify the expression for the gradient.                      #\n",
        "        ############################################################################\n",
        "        loss, dout = softmax_loss(scores,y)\n",
        "        for i in range(self.num_layers,0 ,-1):\n",
        "            w_name = 'w'+str(i)\n",
        "            b_name = 'b'+str(i)\n",
        "            w = self.params[w_name]\n",
        "            b = self.params[b_name]\n",
        "\n",
        "            if i ==self.num_layers:\n",
        "              dx,dw,db = affine_backward(dout,cache_list[i-1])\n",
        "            else:\n",
        "              dx,dw,db = affine_relu_backward(dx,cache_list[i-1])\n",
        "\n",
        "            grads[w_name] = dw + reg * w / self.num_layers * 2\n",
        "            grads[b_name] = db\n",
        "            loss += reg*np.sum(w*w)/self.num_layers\n",
        "        ############################################################################\n",
        "        #                             END OF YOUR CODE                             #\n",
        "        ############################################################################\n",
        "\n",
        "        return loss, grads\n"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEF48Q9ClM4J",
        "outputId": "779e5735-0e55-4a19-e8fc-08caca2bfca1"
      },
      "source": [
        "np.random.seed(231)\n",
        "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
        "X = np.random.randn(N, D)\n",
        "y = np.random.randint(C, size=(N,))\n",
        "\n",
        "for reg in [0, 3.14]:\n",
        "  print('Running check with reg = ', reg)\n",
        "  model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
        "                            reg=reg, weight_scale=5e-2, dtype=np.float64)\n",
        "\n",
        "  loss, grads = model.loss(X, y)\n",
        "  print('Initial loss: ', loss)\n",
        "\n",
        "  for name in sorted(grads):\n",
        "    f = lambda _: model.loss(X, y)[0]\n",
        "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
        "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running check with reg =  0\n",
            "Initial loss:  2.3004790897684924\n",
            "b1 relative error: 5.38e-09\n",
            "b2 relative error: 2.09e-09\n",
            "b3 relative error: 5.80e-11\n",
            "w1 relative error: 1.48e-07\n",
            "w2 relative error: 2.21e-05\n",
            "w3 relative error: 3.53e-07\n",
            "Running check with reg =  3.14\n",
            "Initial loss:  5.4686259229470355\n",
            "b1 relative error: 1.48e-08\n",
            "b2 relative error: 3.68e-09\n",
            "b3 relative error: 2.90e-10\n",
            "w1 relative error: 2.26e-08\n",
            "w2 relative error: 1.00e-07\n",
            "w3 relative error: 2.51e-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        },
        "id": "DfjtUQrqx1Ul",
        "outputId": "c9f6aa00-24f0-41e5-e7df-502e7be2d7be"
      },
      "source": [
        "num_train = 50\n",
        "small_data = {\n",
        "  'X_train': data['X_train'][:num_train],\n",
        "  'y_train': data['y_train'][:num_train],\n",
        "  'X_val': data['X_val'],\n",
        "  'y_val': data['y_val'],\n",
        "}\n",
        "\n",
        "#weight_scale = 1e-2\n",
        "#learning_rate = 1e-4\n",
        "weight_scale = 1e-2\n",
        "learning_rate = 1e-2\n",
        "model = FullyConnectedNet([100, 100],\n",
        "              weight_scale=weight_scale, dtype=np.float64)\n",
        "solver = Solver(model, small_data,\n",
        "                print_every=10, num_epochs=20, batch_size=25,\n",
        "                update_rule='sgd',\n",
        "                optim_config={\n",
        "                  'learning_rate': learning_rate,\n",
        "                }\n",
        "         )\n",
        "solver.train()\n",
        "\n",
        "plt.plot(solver.loss_history, 'o')\n",
        "plt.title('Training loss history')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Training loss')\n",
        "plt.show()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Iteration 1 / 40) loss: 35.630358\n",
            "(Epoch 0 / 20) train acc: 0.320000; val_acc: 0.100000\n",
            "(Epoch 1 / 20) train acc: 0.380000; val_acc: 0.110000\n",
            "(Epoch 2 / 20) train acc: 0.400000; val_acc: 0.167000\n",
            "(Epoch 3 / 20) train acc: 0.620000; val_acc: 0.174000\n",
            "(Epoch 4 / 20) train acc: 0.640000; val_acc: 0.135000\n",
            "(Epoch 5 / 20) train acc: 0.620000; val_acc: 0.158000\n",
            "(Iteration 11 / 40) loss: 23.334474\n",
            "(Epoch 6 / 20) train acc: 0.420000; val_acc: 0.164000\n",
            "(Epoch 7 / 20) train acc: 0.800000; val_acc: 0.163000\n",
            "(Epoch 8 / 20) train acc: 0.740000; val_acc: 0.208000\n",
            "(Epoch 9 / 20) train acc: 0.700000; val_acc: 0.153000\n",
            "(Epoch 10 / 20) train acc: 0.640000; val_acc: 0.171000\n",
            "(Iteration 21 / 40) loss: 15.458946\n",
            "(Epoch 11 / 20) train acc: 0.840000; val_acc: 0.202000\n",
            "(Epoch 12 / 20) train acc: 0.880000; val_acc: 0.187000\n",
            "(Epoch 13 / 20) train acc: 0.860000; val_acc: 0.176000\n",
            "(Epoch 14 / 20) train acc: 0.820000; val_acc: 0.169000\n",
            "(Epoch 15 / 20) train acc: 0.920000; val_acc: 0.211000\n",
            "(Iteration 31 / 40) loss: 10.463823\n",
            "(Epoch 16 / 20) train acc: 0.700000; val_acc: 0.173000\n",
            "(Epoch 17 / 20) train acc: 0.860000; val_acc: 0.181000\n",
            "(Epoch 18 / 20) train acc: 0.880000; val_acc: 0.213000\n",
            "(Epoch 19 / 20) train acc: 0.940000; val_acc: 0.175000\n",
            "(Epoch 20 / 20) train acc: 0.960000; val_acc: 0.171000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        },
        "id": "HyAFSfPEEzrJ",
        "outputId": "ca738afb-37a4-4daa-cb97-8e97b055dbfa"
      },
      "source": [
        "num_train = 50\n",
        "small_data = {\n",
        "  'X_train': data['X_train'][:num_train],\n",
        "  'y_train': data['y_train'][:num_train],\n",
        "  'X_val': data['X_val'],\n",
        "  'y_val': data['y_val'],\n",
        "}\n",
        "\n",
        "learning_rate = 1e-3\n",
        "weight_scale = 1e-5\n",
        "model = FullyConnectedNet([100, 100, 100, 100],\n",
        "                weight_scale=weight_scale, dtype=np.float64)\n",
        "solver = Solver(model, small_data,\n",
        "                print_every=10, num_epochs=20, batch_size=25,\n",
        "                update_rule='sgd',\n",
        "                optim_config={\n",
        "                  'learning_rate': learning_rate,\n",
        "                }\n",
        "         )\n",
        "solver.train()\n",
        "\n",
        "plt.plot(solver.loss_history, 'o')\n",
        "plt.title('Training loss history')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Training loss')\n",
        "plt.show()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Iteration 1 / 40) loss: 2.302606\n",
            "(Epoch 0 / 20) train acc: 0.120000; val_acc: 0.105000\n",
            "(Epoch 1 / 20) train acc: 0.120000; val_acc: 0.119000\n",
            "(Epoch 2 / 20) train acc: 0.160000; val_acc: 0.112000\n",
            "(Epoch 3 / 20) train acc: 0.160000; val_acc: 0.079000\n",
            "(Epoch 4 / 20) train acc: 0.160000; val_acc: 0.079000\n",
            "(Epoch 5 / 20) train acc: 0.160000; val_acc: 0.079000\n",
            "(Iteration 11 / 40) loss: 2.302483\n",
            "(Epoch 6 / 20) train acc: 0.160000; val_acc: 0.079000\n",
            "(Epoch 7 / 20) train acc: 0.160000; val_acc: 0.079000\n",
            "(Epoch 8 / 20) train acc: 0.160000; val_acc: 0.079000\n",
            "(Epoch 9 / 20) train acc: 0.160000; val_acc: 0.112000\n",
            "(Epoch 10 / 20) train acc: 0.160000; val_acc: 0.079000\n",
            "(Iteration 21 / 40) loss: 2.302344\n",
            "(Epoch 11 / 20) train acc: 0.160000; val_acc: 0.079000\n",
            "(Epoch 12 / 20) train acc: 0.160000; val_acc: 0.112000\n",
            "(Epoch 13 / 20) train acc: 0.160000; val_acc: 0.112000\n",
            "(Epoch 14 / 20) train acc: 0.160000; val_acc: 0.112000\n",
            "(Epoch 15 / 20) train acc: 0.160000; val_acc: 0.112000\n",
            "(Iteration 31 / 40) loss: 2.302161\n",
            "(Epoch 16 / 20) train acc: 0.160000; val_acc: 0.112000\n",
            "(Epoch 17 / 20) train acc: 0.160000; val_acc: 0.112000\n",
            "(Epoch 18 / 20) train acc: 0.160000; val_acc: 0.112000\n",
            "(Epoch 19 / 20) train acc: 0.160000; val_acc: 0.112000\n",
            "(Epoch 20 / 20) train acc: 0.160000; val_acc: 0.112000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "F3MG5d69H5dY",
        "outputId": "b8baf58f-5381-42a1-ba93-9f2bc4056f1c"
      },
      "source": [
        "N, D = 4, 5\n",
        "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
        "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
        "v = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
        "\n",
        "config = {'learning_rate': 1e-3, 'velocity': v}\n",
        "next_w, _ = optim.sgd_momentum(w, dw, config=config)\n",
        "print(next_w)\n",
        "expected_next_w = np.asarray([\n",
        "  [ 0.1406,      0.20738947,  0.27417895,  0.34096842,  0.40775789],\n",
        "  [ 0.47454737,  0.54133684,  0.60812632,  0.67491579,  0.74170526],\n",
        "  [ 0.80849474,  0.87528421,  0.94207368,  1.00886316,  1.07565263],\n",
        "  [ 1.14244211,  1.20923158,  1.27602105,  1.34281053,  1.4096    ]])\n",
        "expected_velocity = np.asarray([\n",
        "  [ 0.5406,      0.55475789,  0.56891579, 0.58307368,  0.59723158],\n",
        "  [ 0.61138947,  0.62554737,  0.63970526,  0.65386316,  0.66802105],\n",
        "  [ 0.68217895,  0.69633684,  0.71049474,  0.72465263,  0.73881053],\n",
        "  [ 0.75296842,  0.76712632,  0.78128421,  0.79544211,  0.8096    ]])\n",
        "\n",
        "print('next_w error: ', rel_error(next_w, expected_next_w))\n",
        "print('velocity error: ', rel_error(expected_velocity, config['velocity']))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-245059638e6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   [ 0.75296842,  0.76712632,  0.78128421,  0.79544211,  0.8096    ]])\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'next_w error: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_next_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'velocity error: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_velocity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'velocity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-125-2b0cfacbb9a5>\u001b[0m in \u001b[0;36mrel_error\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrel_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;34m\"\"\" returns relative error \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'float'"
          ]
        }
      ]
    }
  ]
}